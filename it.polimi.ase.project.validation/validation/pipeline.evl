context Pipeline{
	constraint uniqueTasks {
		check: self.tasks -> select(t|t.isTypeOf(CollectionTask)) -> size() <= 1 and 
			self.tasks -> select(t|t.isTypeOf(IntegrationTask)) -> size() <= 1 and
			self.tasks -> select(t|t.isTypeOf(CleaningTask)) -> size() <= 1 and
			self.tasks -> select(t|t.isTypeOf(AnalysisTask)) -> size() <= 1 and
			self.tasks -> select(t|t.isTypeOf(VisualizationTask)) -> size() <= 1 and
			self.tasks -> select(t|t.isTypeOf(ExportTask)) -> size() <= 1
		message: 'There can be at most 1 task per type.'
	}
	
	constraint collectionPresent {
		check: self.tasks -> select(t|t.isTypeOf(CollectionTask)) -> size() > 0
		message: 'Missing mandatory collection task!'
	}
	
	constraint analysisPresent {
		check: self.tasks -> select(t|t.isTypeOf(AnalysisTask)) -> size() > 0
		message: 'Missing mandatory analysis task!'
	}
	
	constraint exportPresent {
		check: self.tasks -> select(t|t.isTypeOf(ExportTask)) -> size() > 0
		message: 'Missing mandatory export task!'
	}
	
	constraint uniqueDataFow {
		check: self.tasks -> reject(t | t.isTypeOf(CollectionTask) or t.isTypeOf(ExportTask)) ->
			forAll(t | t.outgoing -> size() == 1)
		message: "All task except collection task must have a unique outgoing dataflow"
	}
	
	constraint sameDataFlowSchema {
		check: self.tasks -> reject(T1 | T1.isTypeOf(CollectionTask) or T1.isTypeOf(ExportTask)) ->
			forAll(t1 | self.tasks -> reject(T2 | T2.isTypeOf(CollectionTask) or T2.isTypeOf(ExportTask)) ->
			forAll(t2 | t1.outgoing.schema == t2.outgoing.schema))
		message: "Dataflow between tasks must be linked to the same schema"
	}
	
	constraint operationNextIsCleaning {
		check: self.internalDataFlows -> select(d | d.source.isKindOf(CleaningOperation) and 
			d.target.isKindOf(AnalysisOperation)) -> size() == 0
		message: "Cleaning operations can be linked only to cleaning operations"
	}
	
	constraint operationNextIsAnalysis {
		check: self.internalDataFlows -> select(d | d.source.isKindOf(AnalysisOperation) and 
			d.target.isKindOf(CleaningOperation)) -> size() == 0
		message: "Analysis operations can be linked only to analysis operations"
	}
	
	constraint sameInternalDataFlowSchemaCleaning {
		check: self.internalDataFlows -> select(DF1 | DF1.source.isKindOf(CleaningOperation) and 
			DF1.target.isKindOf(CleaningOperation)) -> forAll(d1 | self.internalDataFlows -> 
			select(DF2 | DF2.source.isKindOf(CleaningOperation) and DF2.target.isKindOf(CleaningOperation)) ->
			forAll(d2 | d1 <> d2 implies d1.schema == d2.schema))
		message: "Dataflows between cleaning operations must be linked to the same schema"
	}
		
	constraint sameInternalDataFlowSchemaCleaningAsDataFlow {
		check:  (self.internalDataFlows -> select(d | d.source.isKindOf(CleaningOperation) and d.target.isKindOf(CleaningOperation)) -> size() == 0) or
			(self.internalDataFlows -> select(d | d.source.isKindOf(CleaningOperation) and d.target.isKindOf(CleaningOperation)) -> size() == 1 and 
			self.internalDataFlows -> select(d | d.source.isKindOf(CleaningOperation) and d.target.isKindOf(CleaningOperation)).schema == 
			self.dataFlows -> select(D | D.target.isTypeOf(CleaningTask)).schema) or
			
			(self.internalDataFlows -> select(d | d.source.isKindOf(CleaningOperation) and d.target.isKindOf(CleaningOperation)) -> size() > 1 and
			self.internalDataFlows -> select(DF1 | DF1.source.isKindOf(CleaningOperation) and 
			DF1.target.isKindOf(CleaningOperation)) -> forAll(d1 | self.internalDataFlows -> 
			select(DF2 | DF2.source.isKindOf(CleaningOperation) and DF2.target.isKindOf(CleaningOperation)) ->
			forAll(d2 | d1.schema == d2.schema and 
			d1.schema == select(t | t.isTypeOf(CleaningTask)).incoming.schema)))
		message: "Dataflow between cleaning operations must be linked to the same schema as the external dataflow"
	}
	
	constraint sameInternalDataFlowSchemaAnalysis {
		check: self.internalDataFlows -> select(DF1 | DF1.source.isKindOf(AnalysisOperation) and 
			DF1.target.isKindOf(AnalysisOperation)) -> forAll(d1 | self.internalDataFlows -> 
			select(DF2 | DF2.source.isKindOf(AnalysisOperation) and DF2.target.isKindOf(AnalysisOperation)) ->
			forAll(d2 | d1.schema == d2.schema))
		message: "Dataflows between analysis operations must be linked to the same schema"
	}

	
	constraint sameInternalDataFlowSchemaAnalysisAsDataFlow {
		check: (self.internalDataFlows -> select(d | d.source.isKindOf(AnalysisOperation) and d.target.isKindOf(AnalysisOperation)) -> size() == 0) or
			(self.internalDataFlows -> select(d | d.source.isKindOf(AnalysisOperation) and d.target.isKindOf(AnalysisOperation)) -> size() == 1 and 
			self.internalDataFlows -> select(d | d.source.isKindOf(AnalysisOperation) and d.target.isKindOf(AnalysisOperation)).schema == 
			self.dataFlows -> select(D | D.target.isTypeOf(AnalysisTask)).schema) or
			
			(self.internalDataFlows -> select(d | d.source.isKindOf(AnalysisOperation) and d.target.isKindOf(AnalysisOperation)) -> size() > 1 and
			self.internalDataFlows -> select(DF1 | DF1.source.isKindOf(AnalysisOperation) and 
			DF1.target.isKindOf(AnalysisOperation)) -> forAll(d1 | self.internalDataFlows -> 
			select(DF2 | DF2.source.isKindOf(AnalysisOperation) and DF2.target.isKindOf(AnalysisOperation)) ->
			forAll(d2 | d1<> d2 implies (d1.schema == d2.schema and
			d1.schema == self.tasks -> select(t | t.isTypeOf(AnalysisTask)).incoming.schema))))
		message: "Dataflow between analysis operations must be linked to the same schema as the external dataflow"
	}
	
	constraint DataFlowBetweenCleaningOperation {
		check: self.tasks -> collect(t:CleaningTask | t.operations -> size()) -> sum() == 
			(self.internalDataFlows -> select(d | d.source.isKindOf(CleaningOperation) and 
			d.target.isKindOf(CleaningOperation)) -> size() + 1) or 
			collect(t:CleaningTask | t.operations -> size()) -> sum() == 0
		message: "Missing one or more dataflows between cleaning operations"
	}
	
	constraint DataFlowBetweenAnalysisOperation {
		check: self.tasks -> collect(t:AnalysisTask | t.analysisOperations -> size()) -> sum() == 
			(self.internalDataFlows -> select(d | d.source.isKindOf(AnalysisOperation) and 
			d.target.isKindOf(AnalysisOperation)) -> size() + 1) or 
			self.tasks -> collect(t:AnalysisTask | t.analysisOperations -> size()) -> sum() == 0
		message: "Missing one or more dataflows between analysis operations"
	}
	
}


context CollectionTask{
	constraint initialTask {
		check: self.incoming -> size() == 0
		message: "Collection Task can't have an incoming data flow."
	}
	
	constraint nextTypeCollection {
		check: self.outgoing.target -> select(t |t.isTypeOf(CollectionTask) or t.isTypeOf(VisualizationTask) or
			t.isTypeOf(ExportTask)) -> size() == 0
		message: "Collection task must be linked to integration, cleaning or analysis task"
	}
	
	constraint outgoingDataFlow {
		check: self.outgoing -> size() > 0
		message: "Missing outgoing dataflow for collection task"
	}
}


context IntegrationTask{
	constraint nextTypeIntegration {
		check: self.outgoing.target -> select(t | t.isTypeOf(CollectionTask) or t.isTypeOf(IntegrationTask) or
			t.isTypeOf(VisualizationTask) or t.isTypeOf(ExportTask)) -> size() == 0
		message: "Integration task must be linked to cleaning or analysis task"
	}
}


context CleaningTask{
	constraint nextTypeCleaning {
		check: self.outgoing.target -> reject(t | t.isTypeOf(AnalysisTask)) -> size() == 0
		message: "Cleaning task can be linked only to analysis task"
	}
	
	constraint uniqueInternalDataFlowIn {
		check: self.operations -> forAll(o | o.outgoing -> size() <= 1)
		message: "Cleaning operations can have at maximum one outgoing internal dataflow"
	}
	
	constraint uniqueInternalDataFlowOut {
		check: self.operations -> forAll(o | o.incoming -> size() <= 1)
		message: "Cleaning operations can have at maximum one incoming internal dataflow"
	}
	
}


context AnalysisTask{
	constraint nextTypeAnalysis {
		check: self.outgoing.target -> select(t | t.isTypeOf(CollectionTask) or t.isTypeOf(IntegrationTask) or
			t.isTypeOf(CleaningTask) or t.isTypeOf(AnalysisTask)) -> size() == 0
		message: "Analysis task must be linked to visualization or export task"
	}
	
	constraint uniqueInternalDataFlowIn {
		check: self.analysisOperations -> forAll(o | o.outgoing -> size() <= 1)
		message: "Analyzes operations can have at maximum one outgoing internal dataflow"
	}
	
	constraint uniqueInternalDataFlowOut {
		check: self.analysisOperations -> forAll(o | o.incoming -> size() <= 1)
		message: "Analyzes operations can have at maximum one incoming internal dataflow"
	}
}


context VisualizationTask{
	constraint nextTypeVisualization {
		check: self.outgoing.target -> reject(t | t.isTypeOf(ExportTask)) -> size() == 0
		message: "Visualization task can be linked only to export task"
	}
}


context ExportTask{
	constraint finalTask {
		check: self.outgoing -> size() == 0
		message: "Exporting Task can't have an outgoing data flow."
	}
	
}


context Schema{
	constraint uniqueAttribute {
		check: self.attributes -> forAll (a1 | self.attributes -> forAll (a2 | a1 <> a2 implies a1.name <> a2.name))
		message: "There can't be more attributes with the same name!"
	}	
}


context ComplexAttribute{
	constraint uniqueAttribute {
		check: self.attributes -> forAll (a1 | self.attributes -> forAll (a2 | a1 <> a2 implies a1.name <> a2.name))
		message: "There can't be more attributes with the same name!"
	}	
}


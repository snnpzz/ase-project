
context Pipeline {

	constraint uniqueTasks {
		check: self.tasks -> select(t|t.isTypeOf(CollectionTask)) -> size() <= 1 and 
			self.tasks -> select(t|t.isTypeOf(IntegrationTask)) -> size() <= 1 and
			self.tasks -> select(t|t.isTypeOf(CleaningTask)) -> size() <= 1 and
			self.tasks -> select(t|t.isTypeOf(AnalysisTask)) -> size() <= 1 and
			self.tasks -> select(t|t.isTypeOf(VisualizationTask)) -> size() <= 1 and
			self.tasks -> select(t|t.isTypeOf(ExportTask)) -> size() <= 1
		message: 'There can be at most 1 task per type.'
	}
	
	constraint isCollectionTaskPresent {
		check: self.tasks -> select(t | t.isTypeOf(CollectionTask)) -> size() > 0
		message: 'There must be a Collection Task.'
	}
	
	constraint isAnalysisTaskPresent {
		check: self.tasks -> select(t | t.isTypeOf(AnalysisTask)) -> size() > 0
		message: 'There must be an Analysis Task.'
	}
	
	constraint isExportTaskPresent {
		check: self.tasks -> select(t | t.isTypeOf(ExportTask)) -> size() > 0
		message: 'There must be an Export Task.'
	}
	
	constraint uniqueOutgoingDataFlow {
		check: self.tasks -> reject(t | t.isTypeOf(CollectionTask) or t.isTypeOf(ExportTask)) ->
			forAll(t | t.outgoing -> size() <= 1)
		message: "All tasks, except Collection Task and Export Task, must have a unique outgoing data flow."
	}
	
	constraint isOutgoingDataFlowPresent {
		check: self.tasks -> reject(t | t.isTypeOf(CollectionTask) or t.isTypeOf(ExportTask)) ->
			forAll(t | t.outgoing -> size() > 0)
		message: "Missing outgoing data flow for some tasks"
	}
	
	constraint sameDataFlowSchema {
		check: self.tasks -> reject(T1 | T1.isTypeOf(CollectionTask) or T1.isTypeOf(ExportTask)) ->
			forAll(t1 | self.tasks -> reject(T2 | T2.isTypeOf(CollectionTask) or T2.isTypeOf(ExportTask)) ->
			forAll(t2 | t1.outgoing.schema == t2.outgoing.schema))
		message: "Data Flow between tasks must be linked to the same schema"
	}
	
	constraint operationNextIsCleaning {
		check: self.internalDataFlows -> select(d | d.source.isKindOf(CleaningOperation) and 
			d.target.isKindOf(AnalysisOperation)) -> size() == 0
		message: "Cleaning operations can be linked only to cleaning operations"
	}
	
	constraint operationNextIsAnalysis {
		check: self.internalDataFlows -> select(d | d.source.isKindOf(AnalysisOperation) and 
			d.target.isKindOf(CleaningOperation)) -> size() == 0
		message: "Analysis operations can be linked only to analysis operations"
	}
	
	constraint sameInternalDataFlowSchemaCleaning {
		check: self.internalDataFlows -> select(DF1 | DF1.source.isKindOf(CleaningOperation) and 
			DF1.target.isKindOf(CleaningOperation)) -> forAll(d1 | self.internalDataFlows -> 
			select(DF2 | DF2.source.isKindOf(CleaningOperation) and DF2.target.isKindOf(CleaningOperation)) ->
			forAll(d2 | d1 <> d2 implies d1.schema == d2.schema))
		message: "Dataflows between cleaning operations must be linked to the same schema"
	}
	
	constraint sameInternalDataFlowSchemaAnalysis {
		check: self.internalDataFlows -> select(DF1 | DF1.source.isKindOf(AnalysisOperation) and 
			DF1.target.isKindOf(AnalysisOperation)) -> forAll(d1 | self.internalDataFlows -> 
			select(DF2 | DF2.source.isKindOf(AnalysisOperation) and DF2.target.isKindOf(AnalysisOperation)) ->
			forAll(d2 | d1.schema == d2.schema))
		message: "Dataflows between analysis operations must be linked to the same schema"
	}

	
	constraint sameInternalDataFlowSchemaAnalysisAsDataFlow {
		check: (self.internalDataFlows -> select(d | d.source.isKindOf(AnalysisOperation) and d.target.isKindOf(AnalysisOperation)) -> size() == 0) or
			(self.internalDataFlows -> select(d | d.source.isKindOf(AnalysisOperation) and d.target.isKindOf(AnalysisOperation)) -> size() == 1 and 
			self.internalDataFlows -> select(d | d.source.isKindOf(AnalysisOperation) and d.target.isKindOf(AnalysisOperation)).schema == 
			self.dataFlows -> select(D | D.target.isTypeOf(AnalysisTask)).schema) or
			
			(self.internalDataFlows -> select(d | d.source.isKindOf(AnalysisOperation) and d.target.isKindOf(AnalysisOperation)) -> size() > 1 and
			self.internalDataFlows -> select(DF1 | DF1.source.isKindOf(AnalysisOperation) and 
			DF1.target.isKindOf(AnalysisOperation)) -> forAll(d1 | self.internalDataFlows -> 
			select(DF2 | DF2.source.isKindOf(AnalysisOperation) and DF2.target.isKindOf(AnalysisOperation)) ->
			forAll(d2 | d1<> d2 implies (d1.schema == d2.schema and
			d1.schema == self.dataFlows -> select(D | D.target.isTypeOf(AnalysisTask)).schema))))
		message: "Dataflow between analysis operations must be linked to the same schema as the external data flow"
	}
	
	constraint dataFlowBetweenCleaningOperation {
		check: self.tasks -> collect(t:CleaningTask | t.cleaningOperations -> size()) -> sum() <= 
			(self.internalDataFlows -> select(d | d.source.isKindOf(CleaningOperation) and 
			d.target.isKindOf(CleaningOperation)) -> size() + 1) or 
			collect(t:CleaningTask | t.cleaningOperations -> size()) -> sum() == 0
		message: "Missing one or more data flows between cleaning operations"
	}
	
	constraint dataFlowBetweenAnalysisOperation {
		check: self.tasks -> collect(t:AnalysisTask | t.analysisOperations -> size()) -> sum() <= 
			(self.internalDataFlows -> select(d | d.source.isKindOf(AnalysisOperation) and 
			d.target.isKindOf(AnalysisOperation)) -> size() + 1) or 
			self.tasks -> collect(t:AnalysisTask | t.analysisOperations -> size()) -> sum() == 0
		message: "Missing one or more data flows between analysis operations"
	}
	
	constraint asManySourcesAsManyImportOperations {
		check: self.sources -> size() == (self.tasks -> select(t | t.isTypeOf(CollectionTask)) -> collect(t | t.importOperations -> size()) -> sum())
		message: "There must be as many input sources as many import operations."
			
	}
	
	constraint asManyFilesAsManyExportOperations {
		check: self.files -> size() == (self.tasks -> select(t | t.isTypeOf(ExportTask)) -> collect(t | t.exportOperations -> size()) -> sum())
		message: "There must be as many output files as many export operations."
	}
	
	constraint ifManySourcesIntegration {
		check: (self.sources -> size() == 1) or (self.sources -> size() > 1 and self.tasks -> select(t | t.isTypeOf(IntegrationTask)) -> size() == 1)
		message: "If there are many input sources there must be a integration task"
	}
	
	constraint SourceImportedOnce {
		check: self.sources -> forAll(s | (self.tasks -> select(t | t.isTypeOf(CollectionTask)).importOperations -> forAll(i | i.read == s)) -> size() == 1)
		message: "Imports must be linked to different input sources"
 	}
  	
  	constraint FileExportedOnce {
 		check: self.files -> forAll(f | (self.tasks -> select(t | t.isTypeOf(ExportTask)).exportOperations -> forAll(e | e.write == f)) -> size() == 1)
 		message: "Exports must be linked to different output files"
  	}
	
	constraint uniqueOperationName {
		check: self.tasks -> select(t | t.isTypeOf(AnalysisTask)).analysisOperations -> 
			forAll (a1 | self.tasks -> select(t | t.isTypeOf(AnalysisTask)).analysisOperations -> 
			forAll (a2 | a1 <> a2 implies a1.ID <> a2.ID and self.tasks -> select(t | t.isTypeOf(CleaningTask)).cleaningOperations -> forAll(a3 | a1.ID <> a3.ID) ))
		message: "There can't be more operations (either cleaning or analysis) with the same ID"
	}
}


context CollectionTask {
	constraint initialTask {
		check: self.incoming -> size() == 0
		message: "Collection Task can't have an incoming data flow."
	}
	
	constraint nextTypeCollection {
		check: (self.outgoing -> size() == 1) and (self.outgoing.target -> select(t |t.isTypeOf(CollectionTask) or t.isTypeOf(VisualizationTask) or
			t.isTypeOf(ExportTask)) -> size() == 0) or (self.outgoing -> size() > 1)
		message: "Collection task must be linked to integration, cleaning or analysis task"
	}
	
	constraint outgoingDataFlow {
		check: self.outgoing -> size() > 0
		message: "There must be at least 1 outgoing data flow"
	}
	
	constraint manyDataFlowsFromCollectionAsManyImports {
		check: self.importOperations -> size() == (self.outgoing -> size())
		message:  "In collection task there must be as many outgoing data flows as many input sources"
	}
	
	constraint allOutgoingDataFlowsTargetingSameIntegrationTask {
		check: (self.outgoing -> size() > 1) and (self.outgoing.target -> size() > 1)
		message: "If there are many outgoing data flows from the collection task, all of them must be linked to the same integration task"
	}
	
	constraint pairsOfSchema {
		check: self.importOperations.use -> forAll(s1 | self.outgoing -> select(df | df.schema == s1) -> size() > 0) and
			self.outgoing.schema -> forAll(s2 | self.importOperations -> select(i | i.use == s2) -> size() > 0)
		message: "Links to schema must be paired wrt import and outgoing data flow"
	}
}


context IntegrationTask {

	constraint atLeastOneIntegrationOperation {
		check: self.integrationOperations -> size() >= 1
		message: "There must be at leat 1 integration operation."
	}

	constraint nextTypeIntegration {
		check: self.outgoing.target -> select(t | t.isTypeOf(CollectionTask) or t.isTypeOf(IntegrationTask) or
			t.isTypeOf(VisualizationTask) or t.isTypeOf(ExportTask)) -> size() == 0
		message: "Integration task must be linked to cleaning or analysis task"
	}
		
	constraint integrationNeeded {
		check: self.incoming.source.importOperations -> size() > 1
		message: "Integration task is not needed!"
	}
}


context CleaningTask {

	constraint sameIncomingAndOutgoingSchema {
		check: self.incoming.schema.includesAll(self.outgoing.schema)
		message: "The incoming and the outgoing data flow must have the same schema."
	}
	
	-- TODO
	-- internal data flow have the same schema

	constraint nextTypeCleaning {
		check: self.outgoing.target -> reject(t | t.isTypeOf(AnalysisTask)) -> size() == 0
		message: "Cleaning task can be linked only to analysis task"
	}
	
	constraint uniqueInternalDataFlowIn {
		check: self.CleaningOperations -> forAll(o | o.outgoing -> size() <= 1)
		message: "Cleaning operations can have at maximum one outgoing internal data flow"
	}
	
	constraint uniqueInternalDataFlowOut {
		check: self.cleaningOperations -> forAll(o | o.incoming -> size() <= 1)
		message: "Cleaning operations can have at maximum one incoming internal data flow"
	}
	
	constraint initialCleaningOperation {
		check: self.cleaningOperations -> select(op | op.incoming == null) -> size() == 1
		message: "There can be just one initial cleaning operation. Some internal data flows are wrong"
	}
	
	constraint finalCleaningOperation {
		check: self.cleaningOperations -> select(op | op.outgoing == null) -> size() == 1
		message: "There can be just one final cleaning operation. Some internal data flows are wrong"
	}
	
}

context AnalysisTask{

	constraint nextTypeAnalysis {
		check: self.outgoing.target -> select(t | t.isTypeOf(CollectionTask) or t.isTypeOf(IntegrationTask) or
			t.isTypeOf(CleaningTask) or t.isTypeOf(AnalysisTask)) -> size() == 0
		message: "Analysis task must be linked to visualization or export task"
	}
	
	constraint uniqueInternalDataFlowIn {
		check: self.analysisOperations -> forAll(o | o.outgoing -> size() <= 1)
		message: "Analyzes operations can have at maximum one outgoing internal data flow"
	}
	
	constraint uniqueInternalDataFlowOut {
		check: self.analysisOperations -> forAll(o | o.incoming -> size() <= 1)
		message: "Analyzes operations can have at maximum one incoming internal data flow"
	}
	
	constraint initialAnalysisOperation {
		check: self.analysisOperations -> select(op | op.incoming == null) -> size() == 1
		message: "There can be just one initial analysis operation. Some internal data flows are wrong"
	}
	
	constraint finalAnalysisOperation {
		check: self.analysisOperations -> select(op | op.outgoing == null) -> size() == 1
		message: "There can be just one final analysis operation. Some internal data flows are wrong"
	}
}


context VisualizationTask {

	constraint nextTypeVisualization {
		check: self.outgoing.target -> reject(t | t.isTypeOf(ExportTask)) -> size() == 0
		message: "Visualization task can be linked only to export task"
	}
	
}


context ExportTask {

	constraint finalTask {
		check: self.outgoing -> size() == 0
		message: "Export task can't have an outgoing data flow"
	}
	
}

context Schema {

	constraint uniqueNameAttribute {
		check: self.attributes -> forAll (a1 | self.attributes -> forAll (a2 | a1 <> a2 implies a1.name <> a2.name))
		message: "There can't be more attributes with the same name in the same schema"
	}	
	
	constraint uniqueAttribute {
		check: self.attributes -> forAll (a1 | self.attributes -> select (a2 | a1 == a2) -> size() == 1)
		message: "There can't be many equal attributes in the same schema"
	}	
	
}


context ComplexAttribute {

	constraint uniqueNameAttribute {
		check: self.attributes -> forAll (a1 | self.attributes -> forAll (a2 | a1 <> a2 implies a1.name <> a2.name))
		message: "There can't be more attributes with the same name in the same attribute"
	}	
	
	constraint uniqueAttribute {
		check: self.attributes -> forAll (a1 | self.attributes -> select (a2 | a1 == a2) -> size() == 1)
		message: "There can't be many equal attributes in the same attribute"
	}
	
}



context Pipeline{
	constraint uniqueTasks {
		check: self.tasks -> select(t|t.isTypeOf(CollectionTask)) -> size() <= 1 and 
			self.tasks -> select(t|t.isTypeOf(IntegrationTask)) -> size() <= 1 and
			self.tasks -> select(t|t.isTypeOf(CleaningTask)) -> size() <= 1 and
			self.tasks -> select(t|t.isTypeOf(AnalysisTask)) -> size() <= 1 and
			self.tasks -> select(t|t.isTypeOf(VisualizationTask)) -> size() <= 1 and
			self.tasks -> select(t|t.isTypeOf(ExportTask)) -> size() <= 1
		message: 'There can be at most 1 task per type.'
	}
	
	constraint collectionPresent {
		check: self.tasks -> select(t|t.isTypeOf(CollectionTask)) -> size() > 0
		message: 'Missing mandatory collection task!'
	}
	
	constraint analysisPresent {
		check: self.tasks -> select(t|t.isTypeOf(AnalysisTask)) -> size() > 0
		message: 'Missing mandatory analysis task!'
	}
	
	constraint exportPresent {
		check: self.tasks -> select(t|t.isTypeOf(ExportTask)) -> size() > 0
		message: 'Missing mandatory export task!'
	}
	
	constraint uniqueDataFow {
		check: self.tasks -> reject(t | t.isTypeOf(CollectionTask) or t.isTypeOf(ExportTask)) ->
			forAll(t | t.outgoing -> size() <= 1)
		message: "All task except collection task must have a unique outgoing dataflow"
	}
	
	constraint uniqueDataFow {
		check: self.tasks -> reject(t | t.isTypeOf(CollectionTask) or t.isTypeOf(ExportTask)) ->
			forAll(t | t.outgoing -> size() > 0)
		message: "Missing outgoing dataflow for some tasks"
	}
	
	constraint sameDataFlowSchema {
		check: self.tasks -> reject(T1 | T1.isTypeOf(CollectionTask) or T1.isTypeOf(ExportTask)) ->
			forAll(t1 | self.tasks -> reject(T2 | T2.isTypeOf(CollectionTask) or T2.isTypeOf(ExportTask)) ->
			forAll(t2 | t1.outgoing.schema == t2.outgoing.schema))
		message: "Data Flow between tasks must be linked to the same schema"
	}
	
	constraint operationNextIsCleaning {
		check: self.internalDataFlows -> select(d | d.source.isKindOf(CleaningOperation) and 
			d.target.isKindOf(AnalysisOperation)) -> size() == 0
		message: "Cleaning operations can be linked only to cleaning operations"
	}
	
	constraint operationNextIsAnalysis {
		check: self.internalDataFlows -> select(d | d.source.isKindOf(AnalysisOperation) and 
			d.target.isKindOf(CleaningOperation)) -> size() == 0
		message: "Analysis operations can be linked only to analysis operations"
	}
	
	constraint sameInternalDataFlowSchemaCleaning {
		check: self.internalDataFlows -> select(DF1 | DF1.source.isKindOf(CleaningOperation) and 
			DF1.target.isKindOf(CleaningOperation)) -> forAll(d1 | self.internalDataFlows -> 
			select(DF2 | DF2.source.isKindOf(CleaningOperation) and DF2.target.isKindOf(CleaningOperation)) ->
			forAll(d2 | d1 <> d2 implies d1.schema == d2.schema))
		message: "Dataflows between cleaning operations must be linked to the same schema"
	}
		
	constraint sameInternalDataFlowSchemaCleaningAsDataFlow {
		check:  (self.internalDataFlows -> select(d | d.source.isKindOf(CleaningOperation) and d.target.isKindOf(CleaningOperation)) -> size() == 0) or
			(self.internalDataFlows -> select(d | d.source.isKindOf(CleaningOperation) and d.target.isKindOf(CleaningOperation)) -> size() == 1 and 
			self.internalDataFlows -> select(d | d.source.isKindOf(CleaningOperation) and d.target.isKindOf(CleaningOperation)).schema == 
			self.dataFlows -> select(D | D.target.isTypeOf(CleaningTask)).schema) or
			
			(self.internalDataFlows -> select(d | d.source.isKindOf(CleaningOperation) and d.target.isKindOf(CleaningOperation)) -> size() > 1 and
			self.internalDataFlows -> select(DF1 | DF1.source.isKindOf(CleaningOperation) and 
			DF1.target.isKindOf(CleaningOperation)) -> forAll(d1 | self.internalDataFlows -> 
			select(DF2 | DF2.source.isKindOf(CleaningOperation) and DF2.target.isKindOf(CleaningOperation)) ->
			forAll(d2 | d1.schema == d2.schema and 
			d1.schema == self.dataFlows -> select(D | D.target.isTypeOf(CleaningTask)).schema)))
		message: "Dataflow between cleaning operations must be linked to the same schema as the external dataflow"
	}
	
	constraint sameInternalDataFlowSchemaAnalysis {
		check: self.internalDataFlows -> select(DF1 | DF1.source.isKindOf(AnalysisOperation) and 
			DF1.target.isKindOf(AnalysisOperation)) -> forAll(d1 | self.internalDataFlows -> 
			select(DF2 | DF2.source.isKindOf(AnalysisOperation) and DF2.target.isKindOf(AnalysisOperation)) ->
			forAll(d2 | d1.schema == d2.schema))
		message: "Dataflows between analysis operations must be linked to the same schema"
	}

	
	constraint sameInternalDataFlowSchemaAnalysisAsDataFlow {
		check: (self.internalDataFlows -> select(d | d.source.isKindOf(AnalysisOperation) and d.target.isKindOf(AnalysisOperation)) -> size() == 0) or
			(self.internalDataFlows -> select(d | d.source.isKindOf(AnalysisOperation) and d.target.isKindOf(AnalysisOperation)) -> size() == 1 and 
			self.internalDataFlows -> select(d | d.source.isKindOf(AnalysisOperation) and d.target.isKindOf(AnalysisOperation)).schema == 
			self.dataFlows -> select(D | D.target.isTypeOf(AnalysisTask)).schema) or
			
			(self.internalDataFlows -> select(d | d.source.isKindOf(AnalysisOperation) and d.target.isKindOf(AnalysisOperation)) -> size() > 1 and
			self.internalDataFlows -> select(DF1 | DF1.source.isKindOf(AnalysisOperation) and 
			DF1.target.isKindOf(AnalysisOperation)) -> forAll(d1 | self.internalDataFlows -> 
			select(DF2 | DF2.source.isKindOf(AnalysisOperation) and DF2.target.isKindOf(AnalysisOperation)) ->
			forAll(d2 | d1<> d2 implies (d1.schema == d2.schema and
			d1.schema == self.dataFlows -> select(D | D.target.isTypeOf(AnalysisTask)).schema))))
		message: "Dataflow between analysis operations must be linked to the same schema as the external dataflow"
	}
	
	constraint dataFlowBetweenCleaningOperation {
		check: self.tasks -> collect(t:CleaningTask | t.cleaningOperations -> size()) -> sum() <= 
			(self.internalDataFlows -> select(d | d.source.isKindOf(CleaningOperation) and 
			d.target.isKindOf(CleaningOperation)) -> size() + 1) or 
			collect(t:CleaningTask | t.cleaningOperations -> size()) -> sum() == 0
		message: "Missing one or more data flows between cleaning operations"
	}
	
	constraint dataFlowBetweenAnalysisOperation {
		check: self.tasks -> collect(t:AnalysisTask | t.analysisOperations -> size()) -> sum() <= 
			(self.internalDataFlows -> select(d | d.source.isKindOf(AnalysisOperation) and 
			d.target.isKindOf(AnalysisOperation)) -> size() + 1) or 
			self.tasks -> collect(t:AnalysisTask | t.analysisOperations -> size()) -> sum() == 0
		message: "Missing one or more data flows between analysis operations"
	}
	
	constraint asManySourcesAsManyImportOperations {
		check: self.sources -> size() == (self.tasks -> select(t | t.isTypeOf(CollectionTask)).importOperations) -> size()
		message: "There must be as many input sources as many import operations."
	}
	
	constraint asManyFilesAsManyExportOperations {
		check: self.files -> size() == (self.tasks -> select(t | t.isTypeOf(ExportTask)).exportOperations) -> size()
		message: "There must be as many output files as many export operations."
	}
	
	constraint ifManySourcesIntegration {
		check: (self.sources -> size() == 1) or (self.sources -> size() > 1 and self.tasks -> select(t | t.isTypeOf(IntegrationTask)) -> size() == 1)
		message: "If there are many input sources there must be a integration task"
	}
	
	constraint SourceImportedOnce {
		check: self.sources -> forAll(s | (self.tasks -> select(t | t.isTypeOf(CollectionTask)).importOperations -> forAll(i | i.read == s)) -> size() == 1)
		message: "Imports must be linked to different input sources"
 	}
  	
  	constraint FileExportedOnce {
 		check: self.files -> forAll(f | (self.tasks -> select(t | t.isTypeOf(ExportTask)).exportOperations -> forAll(e | e.write == f)) -> size() == 1)
 		message: "Exports must be linked to different output files"
  	}
}


context CollectionTask{
	constraint initialTask {
		check: self.incoming -> size() == 0
		message: "Collection Task can't have an incoming data flow."
	}
	
	constraint nextTypeCollection {
		check: (self.outgoing -> size() == 1) and (self.outgoing.target -> select(t |t.isTypeOf(CollectionTask) or t.isTypeOf(VisualizationTask) or
			t.isTypeOf(ExportTask)) -> size() == 0) or (self.outgoing -> size() > 1)
		message: "Collection task must be linked to integration, cleaning or analysis task"
	}
	
	constraint outgoingDataFlow {
		check: self.outgoing -> size() > 0
		message: "Missing outgoing dataflow for collection task"
	}
	
	constraint manyDataFlowsFromCollectionAsManyImports {
		check: self.importOperations -> size() == self.outgoing -> size()
		message: "In collection task there must be as many outgoing dataflows as many input sources"
	}
	
	constraint manyDataFlowsAllToIntegration {
		check: (self.outgoing -> size() == 1) or ((self.outgoing -> size() > 1) and (self.outgoing -> forAll(df | df.target.isTypeOf(IntegrationTask))))
		message: "If there are many outgoing dataflows from collection task, all of them must be linked to integration task"
	}
	
	constraint pairsOfSchema {
		check: self.importOperations.impUses -> forAll(s1 | self.outgoing -> select(df | df.schema == s1) -> size() > 0) and
			self.outgoing.schema -> forAll(s2 | self.importOperations -> select(i | i.impUses == s2) -> size() > 0)
		message: "Links to schema must be paired wrt import and outgoing dataflow"
	}
}


context IntegrationTask{
	constraint nextTypeIntegration {
		check: self.outgoing.target -> select(t | t.isTypeOf(CollectionTask) or t.isTypeOf(IntegrationTask) or
			t.isTypeOf(VisualizationTask) or t.isTypeOf(ExportTask)) -> size() == 0
		message: "Integration task must be linked to cleaning or analysis task"
	}
	
	constraint canIntegrate {
		check: self.attributes -> forAll(a1 | self.incoming.source.importOperations.impUses.attributes -> forAll(a2 | a1 == a2)) 
		message: "The attribute(s) for integration task must be present in all source schemas"
	}
	
	constraint integrationNeeded {
		check: self.incoming.source.importOperations -> size() > 1
		message: "Integration task is not needed!"
	}
}


context CleaningTask{
	constraint nextTypeCleaning {
		check: self.outgoing.target -> reject(t | t.isTypeOf(AnalysisTask)) -> size() == 0
		message: "Cleaning task can be linked only to analysis task"
	}
	
	constraint uniqueInternalDataFlowIn {
		check: self.CleaningOperations -> forAll(o | o.outgoing -> size() <= 1)
		message: "Cleaning operations can have at maximum one outgoing internal data flow"
	}
	
	constraint uniqueInternalDataFlowOut {
		check: self.cleaningOperations -> forAll(o | o.incoming -> size() <= 1)
		message: "Cleaning operations can have at maximum one incoming internal data flow"
	}
	
	constraint initialCleaningOperation {
		check: self.cleaningOperations -> select(op | op.incoming == null) -> size() == 1
		message: "There can be just one initial cleaning operation. Some internal data flows are wrong"
	}
	
	constraint finalCleaningOperation {
		check: self.cleaningOperations -> select(op | op.outgoing == null) -> size() == 1
		message: "There can be just one final cleaning operation. Some internal data flows are wrong"
	}
	
}


context AnalysisTask{
	constraint nextTypeAnalysis {
		check: self.outgoing.target -> select(t | t.isTypeOf(CollectionTask) or t.isTypeOf(IntegrationTask) or
			t.isTypeOf(CleaningTask) or t.isTypeOf(AnalysisTask)) -> size() == 0
		message: "Analysis task must be linked to visualization or export task"
	}
	
	constraint uniqueInternalDataFlowIn {
		check: self.analysisOperations -> forAll(o | o.outgoing -> size() <= 1)
		message: "Analyzes operations can have at maximum one outgoing internal dataflow"
	}
	
	constraint uniqueInternalDataFlowOut {
		check: self.analysisOperations -> forAll(o | o.incoming -> size() <= 1)
		message: "Analyzes operations can have at maximum one incoming internal data flow"
	}
	
	constraint initialAnalysisOperation {
		check: self.analysisOperations -> select(op | op.incoming == null) -> size() == 1
		message: "There can be just one initial analysis operation. Some internal data flows are wrong"
	}
	
	constraint finalAnalysisOperation {
		check: self.analysisOperations -> select(op | op.outgoing == null) -> size() == 1
		message: "There can be just one final analysis operation. Some internal data flows are wrong"
	}
}


context VisualizationTask{
	constraint nextTypeVisualization {
		check: self.outgoing.target -> reject(t | t.isTypeOf(ExportTask)) -> size() == 0
		message: "Visualization task can be linked only to export task"
	}
}


context ExportTask{
	constraint finalTask {
		check: self.outgoing -> size() == 0
		message: "Export task can't have an outgoing data flow"
	}
	
}


context Schema{
	constraint uniqueNameAttribute {
		check: self.attributes -> forAll (a1 | self.attributes -> forAll (a2 | a1 <> a2 implies a1.name <> a2.name))
		message: "There can't be more attributes with the same name in the same schema"
	}	
	
	constraint uniqueAttribute {
		check: self.attributes -> forAll (a1 | self.attributes -> select (a2 | a1 == a2) -> size() == 0)
		message: "There can't be many equal attributes in the same schema"
	}	
}


context ComplexAttribute{
	constraint uniqueNameAttribute {
		check: self.attributes -> forAll (a1 | self.attributes -> forAll (a2 | a1 <> a2 implies a1.name <> a2.name))
		message: "There can't be more attributes with the same name in the same attribute"
	}	
	
	constraint uniqueAttribute {
		check: self.attributes -> forAll (a1 | self.attributes -> select (a2 | a1 == a2) -> size() == 0)
		message: "There can't be many equal attributes in the same attribute"
	}
}



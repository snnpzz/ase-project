
context Pipeline {

	constraint uniqueTasks {
		check: self.tasks -> select(t|t.isTypeOf(CollectionTask)) -> size() <= 1 and 
			self.tasks -> select(t|t.isTypeOf(IntegrationTask)) -> size() <= 1 and
			self.tasks -> select(t|t.isTypeOf(CleaningTask)) -> size() <= 1 and
			self.tasks -> select(t|t.isTypeOf(AnalysisTask)) -> size() <= 1 and
			self.tasks -> select(t|t.isTypeOf(VisualizationTask)) -> size() <= 1 and
			self.tasks -> select(t|t.isTypeOf(ExportTask)) -> size() <= 1
		message: 'There can be at most 1 task per type.'
	}
	
	constraint isCollectionTaskPresent {
		check: self.tasks -> select(t | t.isTypeOf(CollectionTask)) -> size() > 0
		message: 'There must be a Collection Task.'
	}
	
	constraint isAnalysisTaskPresent {
		check: self.tasks -> select(t | t.isTypeOf(AnalysisTask)) -> size() > 0
		message: 'There must be an Analysis Task.'
	}
	
	constraint isExportTaskPresent {
		check: self.tasks -> select(t | t.isTypeOf(ExportTask)) -> size() > 0
		message: 'There must be an Export Task.'
	}
	
	constraint uniqueOutgoingDataFlow {
		check: self.tasks -> reject(t | t.isTypeOf(CollectionTask) or t.isTypeOf(ExportTask)) ->
			forAll(t | t.outgoing -> size() <= 1)
		message: "All tasks, except Collection Task and Export Task, must have a unique outgoing data flow."
	}
	
	constraint isOutgoingDataFlowPresent {
		check: self.tasks -> reject(t | t.isTypeOf(CollectionTask) or t.isTypeOf(ExportTask)) ->
			forAll(t | t.outgoing -> size() > 0)
		message: "Missing outgoing data flow for some tasks"
	}
	
	constraint operationNextIsCleaning {
		check: self.internalDataFlows -> select(d | d.source.isKindOf(CleaningOperation) and 
			d.target.isKindOf(AnalysisOperation)) -> size() == 0
		message: "Cleaning operations can be linked only to cleaning operations"
	}
	
	constraint operationNextIsAnalysis {
		check: self.internalDataFlows -> select(d | d.source.isKindOf(AnalysisOperation) and 
			d.target.isKindOf(CleaningOperation)) -> size() == 0
		message: "Analysis operations can be linked only to analysis operations"
	}
	
	constraint dataFlowBetweenCleaningOperation {
		check: self.tasks -> collect(t:CleaningTask | t.cleaningOperations -> size()) -> sum() <= 
			(self.internalDataFlows -> select(d | d.source.isKindOf(CleaningOperation) and 
			d.target.isKindOf(CleaningOperation)) -> size() + 1) or 
			collect(t:CleaningTask | t.cleaningOperations -> size()) -> sum() == 0
		message: "Missing one or more data flows between cleaning operations"
	}
	
	constraint dataFlowBetweenAnalysisOperation {
		check: self.tasks -> collect(t:AnalysisTask | t.analysisOperations -> size()) -> sum() <= 
			(self.internalDataFlows -> select(d | d.source.isKindOf(AnalysisOperation) and 
			d.target.isKindOf(AnalysisOperation)) -> size() + 1) or 
			self.tasks -> collect(t:AnalysisTask | t.analysisOperations -> size()) -> sum() == 0
		message: "Missing one or more data flows between analysis operations"
	}
	
	constraint asManySourcesAsManyImportOperations {
		check: self.sources -> size() == (self.tasks -> select(t | t.isTypeOf(CollectionTask)) -> collect(t | t.importOperations -> size()) -> sum())
		message: "There must be as many input sources as many import operations."
			
	}
	
	constraint asManyFilesAsManyExportOperations {
		check: self.files -> size() == (self.tasks -> select(t | t.isTypeOf(ExportTask)) -> collect(t | t.exportOperations -> size()) -> sum())
		message: "There must be as many output files as many export operations."
	}
	
	constraint ifManySourcesIntegration {
		check: (self.sources -> size() == 1) or (self.sources -> size() > 1 and self.tasks -> select(t | t.isTypeOf(IntegrationTask)) -> size() == 1)
		message: "If there are many input sources there must be a integration task"
	}
	
	constraint SourceImportedOnce {
		check: self.sources -> forAll(s | (self.tasks -> select(t | t.isTypeOf(CollectionTask)).importOperations -> forAll(i | i.read == s)) -> size() == 1)
		message: "Imports must be linked to different input sources"
 	}
  	
  	constraint FileExportedOnce {
 		check: self.files -> forAll(f | (self.tasks -> select(t | t.isTypeOf(ExportTask)).exportOperations -> forAll(e | e.write == f)) -> size() == 1)
 		message: "Exports must be linked to different output files"
  	}
  	
  	constraint formatExportedOnce {
  		check: self.files.format -> forAll(f1 | self.files.format -> select(f2 | f2 == f1) -> size() == 1)
  		message: "Each format can be exported at most once"
  	}
  	
  	constraint ExportedFilesNameAreDifferent {
  		check: self.files -> forAll(f1 | self.files -> forAll(f2 | f1 <> f2 implies f1.name <> f2.name))
  		message: "Exported files must have different names"
  	}
	
	constraint uniqueOperationName {
		check: self.tasks -> select(t | t.isTypeOf(AnalysisTask)).analysisOperations -> 
			forAll (a1 | self.tasks -> select(t | t.isTypeOf(AnalysisTask)).analysisOperations -> 
			forAll (a2 | a1 <> a2 implies a1.ID <> a2.ID and self.tasks -> select(t | t.isTypeOf(CleaningTask)).cleaningOperations -> forAll(a3 | a1.ID <> a3.ID) ))
		message: "There can't be more operations (either cleaning or analysis) with the same ID"
	}
}


context CollectionTask {
	constraint initialTask {
		check: self.incoming -> size() == 0
		message: "Collection Task can't have an incoming data flow."
	}
	
	constraint nextTypeCollection {
		check: (self.outgoing -> size() == 1) and (self.outgoing.target -> select(t |t.isTypeOf(CollectionTask) or t.isTypeOf(VisualizationTask) or
			t.isTypeOf(ExportTask)) -> size() == 0) or (self.outgoing -> size() > 1)
		message: "Collection task must be linked to integration, cleaning or analysis task"
	}
	
	constraint outgoingDataFlow {
		check: self.outgoing -> size() > 0
		message: "There must be at least 1 outgoing data flow"
	}
	
	constraint manyDataFlowsFromCollectionAsManyImports {
		check: self.importOperations -> size() == (self.outgoing -> size())
		message:  "In collection task there must be as many outgoing data flows as many input sources"
	}
	
	constraint allOutgoingDataFlowsTargetingSameIntegrationTask {
		check: (self.outgoing -> size() > 1) and (self.outgoing.target -> size() > 1)
		message: "If there are many outgoing data flows from the collection task, all of them must be linked to the same integration task"
	}
	
	constraint pairsOfSchema {
		check: self.importOperations.use -> forAll(s1 | self.outgoing -> select(df | df.schema == s1) -> size() > 0) and
			self.outgoing.schema -> forAll(s2 | self.importOperations -> select(i | i.use == s2) -> size() > 0)
		message: "Links to schema must be paired wrt import and outgoing data flow"
	}
}


context IntegrationTask {

	constraint nextTypeIntegration {
		check: self.outgoing.target -> select(t | t.isTypeOf(CollectionTask) or t.isTypeOf(IntegrationTask) or
			t.isTypeOf(VisualizationTask) or t.isTypeOf(ExportTask)) -> size() == 0
		message: "Integration task must be linked to cleaning or analysis task"
	}
		
	constraint integrationNeeded {
		check: self.incoming.source.importOperations -> size() > 1
		message: "Integration task is not needed!"
	}
	
	constraint needAtLeast2AttributesForEachOperation {
		check: self.integrationOperations -> forAll(op | op.attributes -> size() >= 2)
		message: "There must be 2 attributes for each integration operation"
	}
}


context CleaningTask {

	constraint sameIncomingAndOutgoingSchema {
		check: self.incoming.schema.includesAll(self.outgoing.schema)
		message: "The incoming and the outgoing data flow must have the same schema."
	}

	constraint nextTypeCleaning {
		check: self.outgoing.target -> reject(t | t.isTypeOf(AnalysisTask)) -> size() == 0
		message: "Cleaning task can be linked only to analysis task"
	}
	
	constraint uniqueInternalDataFlowOut {
		check: self.CleaningOperations -> forAll(o | o.outgoing -> size() <= 1)
		message: "Cleaning operations can have at maximum one outgoing internal data flow"
	}
	
	constraint uniqueInternalDataFlowIn {
		check: self.cleaningOperations -> forAll(o | o.incoming -> size() <= 1)
		message: "Cleaning operations can have at maximum one incoming internal data flow"
	}
	
	constraint initialCleaningOperation {
		check: self.cleaningOperations -> select(op | op.incoming == null) -> size() == 1
		message: "There can be just one initial cleaning operation. Some internal data flows are wrong"
	}
	
	constraint finalCleaningOperation {
		check: self.cleaningOperations -> select(op | op.outgoing == null) -> size() == 1
		message: "There can be just one final cleaning operation. Some internal data flows are wrong"
	}
	
}

context AnalysisTask{

	constraint nextTypeAnalysis {
		check: self.outgoing.target -> select(t | t.isTypeOf(CollectionTask) or t.isTypeOf(IntegrationTask) or
			t.isTypeOf(CleaningTask) or t.isTypeOf(AnalysisTask)) -> size() == 0
		message: "Analysis task must be linked to visualization or export task"
	}
	
	constraint uniqueInternalDataFlowIn {
		check: self.analysisOperations -> forAll(o | o.outgoing -> size() <= 1)
		message: "Analyzes operations can have at maximum one outgoing internal data flow"
	}
	
	constraint uniqueInternalDataFlowOut {
		check: self.analysisOperations -> forAll(o | o.incoming -> size() <= 1)
		message: "Analyzes operations can have at maximum one incoming internal data flow"
	}
	
	constraint initialAnalysisOperation {
		check: self.analysisOperations -> select(op | op.incoming == null) -> size() == 1
		message: "There can be just one initial analysis operation. Some internal data flows are wrong"
	}
	
	constraint finalAnalysisOperation {
		check: self.analysisOperations -> select(op | op.outgoing == null) -> size() == 1
		message: "There can be just one final analysis operation. Some internal data flows are wrong"
	}
	
	constraint outgoingDataFlowHasGeneratedAttributes {
		check: self.outgoing.schema.attributes.includesAll(self.analysisOperations.outputAttributes)
		message: "The outgoing dataflow schema of analysis doesn't respect the generated attributes" 
	}
	
	constraint outgoingDataFlowHasRightSchema {
		check: self.outgoing.schema.attributes.includesAll(self.analysisOperations.outputAttributes) and
			self.outgoing.schema.attributes.includesAll(self.incoming.schema.attributes)
		message: "The outgoing dataflow schema is wrong" 
	}
	
	constraint outputAttributeNameIsNotUsed {
		check: self.analysisOperation.outputAttributes -> forAll(attr1 | self.analysisOperation.outputAttributes ->
			forAll(attr2 | attr1 <> attr2 implies attr1.name <> attr2.name))
		message: "Output attributes of analysis operation must have different names"
	}
}


context VisualizationTask {

	constraint nextTypeVisualization {
		check: self.outgoing.target -> reject(t | t.isTypeOf(ExportTask)) -> size() == 0
		message: "Visualization task can be linked only to export task"
	}
	
	constraint sameIncomingAndOutgoingSchema {
		check: self.incoming.schema.includesAll(self.outgoing.schema)
		message: "The incoming and the outgoing data flow must have the same schema."
	}
	
}


context ExportTask {

	constraint finalTask {
		check: self.outgoing -> size() == 0
		message: "Export task can't have an outgoing data flow"
	}
	
}

context Schema {

	constraint uniqueNameAttribute {
		check: self.attributes -> forAll (a1 | self.attributes -> forAll (a2 | a1 <> a2 implies a1.name <> a2.name))
		message: "There can't be more attributes with the same name in the same schema"
	}	
	
	constraint uniqueAttribute {
		check: self.attributes -> forAll (a1 | self.attributes -> select (a2 | a1 == a2) -> size() == 1)
		message: "There can't be many equal attributes in the same schema"
	}	
	
}


context ComplexAttribute {

	constraint uniqueNameAttribute {
		check: self.attributes -> forAll (a1 | self.attributes -> forAll (a2 | a1 <> a2 implies a1.name <> a2.name))
		message: "There can't be more attributes with the same name in the same attribute"
	}	
	
	constraint uniqueAttribute {
		check: self.attributes -> forAll (a1 | self.attributes -> select (a2 | a1 == a2) -> size() == 1)
		message: "There can't be many equal attributes in the same attribute"
	}
	
}


context ClusteringAnalysisOperation {

	constraint KisSet{
		check: self.k <> 0
		message: "K parameter for clustering analysis operation must be set"
	}
	
}

